# ==========================
# CURRENT / IN-PROGRESS (concise)
# ==========================

- key: rl-telemetry
  featured: false
  status: current
  toc_title: Integrated RL Simulation & Telemetry Platform
  title: Integrated RL Simulation & Telemetry Platform
  dates:
    start: 2025-09-01
  role: Developer & Research Engineer
  domain: Reinforcement Learning
  one_liner: >
    Unified RL pipeline for 2D/3D tasks with live telemetry and reproducible runs.
  summary_short: >
    MVP under development with PPO baselines, config-driven runs, and a live dashboard streaming metrics and frames.
  tags: [RL platforms, Reproducibility, Telemetry, PPO, Robotics]
  stack: [Python, PyTorch, Gymnasium, Unity ML-Agents, PyBullet, Flask/Streamlit, WebSocket, Docker]
  impact_metrics:
    - { label: Prototype, value: "MVP", note: "PPO + live telemetry (2D)" }
    - { label: Coverage, value: "2D → 3D", note: "Gridworlds then PyBullet/Unity" }
    - { label: Runs, value: "Config-first", note: "Seeds, manifests, checkpoints" }
  highlights:
    - Unified reset/step/render API across tasks
    - WebSocket telemetry to dashboard (metrics, plots, frames)
    - Artefact logging for reproducibility
    - Extensible interface for new environments
  case_study:
    problem: >
      Fragmented RL tooling makes runs hard to compare and reproduce.
    approach: >
      Config-first experiments with PPO/tabular; live telemetry to a Streamlit/Flask UI; standardised artefacts.
    results: >
      Baseline PPO + live streaming operational on 2D tasks; 3D envs integrated and tuning in progress.
    next_steps:
      - Unity ML-Agents integration and multi-agent experiments
      - Open-source packaging with examples and docs
      - Self-play and curriculum support
  links: { repo: "", docs: "", demo: "", video: "", paper: "", dataset: "" }
  media:
    hero: { src: /assets/projects/rl-telemetry/hero.png, alt: "RL platform system diagram", caption: "Planned architecture and telemetry" }
    gallery: []
  responsibilities:
    - Designed architecture and PPO baseline
    - Built logging, checkpointing, and telemetry
    - Integrated Gymnasium and PyBullet
  team: []

- key: archlinux-migration
  featured: false
  status: current
  toc_title: Arch Linux Migration & Dev Environment Automation
  title: Arch Linux Migration & Dev Environment Automation
  dates:
    start: 2025-10-01
  role: Systems Engineer (personal infrastructure)
  domain: Developer Experience | Linux
  one_liner: >
    NVIDIA 3060 laptop on Arch: reproducible, CUDA-ready, one-command bootstrap.
  summary_short: >
    Scripted install (bootloader→CUDA→Docker→dotfiles) plus an optional Ansible playbook for idempotent rebuilds.
  tags: [Arch Linux, CUDA, Docker, Dotfiles, Automation, Ansible]
  stack: [Arch Linux, systemd-boot, btrfs, pacman/paru, NVIDIA + CUDA, Docker, Python, Make, Ansible]
  impact_metrics:
    - { label: Bootstrap, value: "≤15 min", note: "Bare OS → dev ready" }
    - { label: Repro, value: "1 command", note: "make bootstrap" }
    - { label: GPU, value: "CUDA OK", note: "Validated on host + Docker" }
  highlights:
    - Idempotent shell bootstrap for packages, drivers, and tools
    - Versioned dotfiles (shell/editor/terminal/WM)
    - Docker workflow for RL/robotics stacks
    - Ansible playbook with roles, handlers, and tags against a local or remote inventory
  case_study:
    problem: >
      Windows slowed GPU workflows and reproducibility; I wanted a lean, rebuildable dev box.
    approach: >
      Automate the full stack (bootloader, FS, drivers, packages, dotfiles, containers, Python). Mirror steps in Ansible for unattended rebuilds.
    results: >
      One-command setup with working CUDA; faster context switching; playbook enables headless or multi-host rebuilds.
    next_steps:
      - Publish dotfiles/bootstrap with CI checks
      - Optional Nix packaging for brittle toolchains
      - Scripted backup/sync across machines
  links: { repo: "", docs: "", demo: "", video: "", paper: "", dataset: "" }
  media:
    hero: { src: /assets/projects/archlinux/hero.png, alt: "Arch desktop with terminal and telemetry", caption: "Reproducible CUDA dev environment" }
    gallery: []
  responsibilities:
    - Authored bootstrap and dotfiles
    - Validated CUDA on host and Docker
    - Wrote Ansible roles and inventory
  team: []

- key: phd-planning
  featured: false
  status: current
  toc_title: PhD Planning — Robot Learning for Assistive Navigation
  title: PhD Planning — Robot Learning for Assistive Navigation
  dates:
    start: 2025-09-01
  role: Candidate (self-directed research planning)
  domain: Robot Learning | HRI
  one_liner: >
    Long-term interest: safe, co-adaptive RL for assistive navigation—pursued alongside a full-time role.
  summary_short: >
    Proposals, reading plan, small prototypes; outreach to Brighton, Nottingham, and European HRI labs.
  tags: [Safe RL, Co-adaptive control, Intent estimation, Haptic guidance, Reproducibility]
  stack: [Python, PyTorch, ROS, RTAB-Map, Unity/Gazebo, Jupyter, Zotero/Obsidian]
  impact_metrics:
    - { label: Proposals, value: "2–3", note: "Framing + methods" }
    - { label: Prototypes, value: "2", note: "Navigation + eval demos" }
    - { label: Reading, value: "80–120", note: "With notes" }
  highlights:
    - Problem axes defined (uncertainty, perception ambiguity, human-in-loop)
    - Reproducible experiment & evaluation plan
    - Prototypes to de-risk perception and reward design
  case_study:
    problem: >
      Assistive navigation needs policies that adapt safely to people and uncertainty.
    approach: >
      Explore co-adaptive safe RL and preference-informed guidance; evaluate with simulation metrics and human-centred measures.
    results: >
      Two proposal drafts refined; reproducibility harness in place; supervisor shortlist identified.
    next_steps:
      - Supervisor alignment and pilot planning
      - Richer perception; preference learning studies
  links: { repo: "", docs: "", demo: "", video: "", paper: "", dataset: "" }
  media:
    hero: { src: /assets/projects/phd/hero.png, alt: "Planning board and prototype screenshots", caption: "Themes, prototypes, and evaluation plan" }
    gallery: []
  responsibilities:
    - Drafted proposals and reading plan
    - Built small prototypes and harness
    - Contacted prospective labs
  team:
    - { name: "Dr. Yanan Li", role: "Prospective supervisor (interest)", link: "" }
    - { name: "Dr. Shou-Han Zhou", role: "Academic mentor (Cardiff)", link: "" }

# ==========================
# PAST / COMPLETED (expanded)
# ==========================

- key: walkaide
  featured: true
  status: past
  toc_title: Wearable Haptic Navigation System (RGB-D VSLAM)
  title: The Design and Evaluation of Haptic Feedback Methods and Environmental Impacts on a Wearable Navigation System
  dates:
    start: 2024-09-01
    end: 2025-05-01
  role: Lead Developer (solo project)
  domain: Robotics | Assistive Robotics | Haptics | VSLAM | Human Factors
  one_liner: >
    Directional haptic cues with RGB-D VSLAM reduced collisions and improved success in blindfolded navigation trials.
  summary_short: >
    Built a wearable navigation system (RGB-D VSLAM, APF navigation, haptic actuation) with EEG event logging. Trials showed
    compass-style cues outperformed pull-based straps on success, safety, and reaction time.
  tags:
    - SLAM
    - ROS Noetic
    - Python (custom ROS nodes, PCL)
    - RTAB-Map (RGB-D VSLAM)
    - Intel RealSense D435i
    - Arduino Nano 33 BLE
    - LattePanda Delta 3
    - Raspberry Pi 4
    - EEG logging (Emotiv, CYKIT)
    - Artificial Potential Fields (navigation)
  stack:
    - ROS Noetic
    - Python (custom ROS nodes, PCL)
    - RTAB-Map (RGB-D VSLAM)
    - Intel RealSense D435i
    - Arduino Nano 33 BLE
    - EEG logging (Emotiv, CYKIT)
  impact_metrics:
    - { label: Success rate, value: "83–77% vs 50–66%", note: "Compass vs pulling" }
    - { label: Collisions per trial, value: "0–0.42 vs up to 1.17", note: "Compass vs pulling" }
    - { label: Reaction time, value: "3.43–3.67 s vs ~4.5–4.9 s", note: "Compass vs pulling feedback" }
    - { label: Participants, value: "4", note: "Blindfolded indoor trials (textured vs plain)" }
  highlights:
    - End-to-end wearable system with RGB-D perception, VSLAM, haptic actuation, and APF
    - Controlled comparison of compass vs pull-based feedback
    - EEG event logging aligned to haptic/motor cues for later analysis
    - Reproducible ROS/Arduino testbed for assistive robotics
  case_study:
    problem: |
      Indoors, GPS is unreliable. Can haptic compass cues paired with RGB-D SLAM guide users more clearly
      than pull-based straps, and what environmental factors matter?
    approach: |
      ROS pipeline with RealSense RGB-D perception, RTAB-Map localisation, APF navigation, and Arduino-driven actuators.
      Two feedback modalities were implemented: (i) compass pressure with a back reference, and (ii) tightening pull straps.
      All cues and motor commands were timestamped and logged, together with EEG event markers, for later workload analysis.
    experiments: |
      Four blindfolded participants navigated fixed routes in textured and plain rooms with both systems.
      Metrics included success, collisions, odometry loss, reaction time, and qualitative feedback. SLAM stability was
      analysed under texture and turning-rate changes.
    results: |
      Compass cues achieved higher success (83–77% vs 50–66%), fewer collisions (0–0.42 vs ≤1.17), and faster reactions
      (3.4–3.7 s vs ~4.5–4.9 s). Textured environments stabilised VSLAM, while rapid turns remained a failure mode.
      Participants reported compass cues clearer and more intuitive; pulling was rated more comfortable.
    challenges:
      - Limited servo torque constrained haptic salience
      - VSLAM degraded during rapid turns and in plain environments
      - Small sample size limited statistical power
      - Multi-device ROS over Wi-Fi/TF frames introduced timing complexity
    learnings:
      - Body-referenced compass cues are clearer than pull-based cues indoors
      - Visual texture drives VSLAM robustness more than lighting
      - Event-synchronised EEG logging is practical and informative for later analysis
    next_steps:
      - Lighter, higher-torque actuators with adaptive feedback
      - Multi-camera or fusion for robust SLAM; larger participant study
  links:
    repo: https://github.com/tyecam1/Mechatronic-Walkaide
    docs: ""
    demo: ""
    video: ""
    paper: https://github.com/tyecam1/Mechatronic-Walkaide/blob/main/Report%20Write%20Up/WearableNavigationAid-FinalReport.pdf
    dataset: ""
  media:
    hero: { src: /assets/projects/walkaide/hero.jpg, alt: "Participant wearing haptic harness with RGB-D camera", caption: "Prototype wearable navigation system" }
    gallery: []
  responsibilities:
    - Designed system architecture and custom ROS nodes
    - Implemented APF navigation and haptic control
    - Integrated perception, mapping, and Arduino feedback
    - Implemented EEG logging & synchronisation; handed over for analysis
  team: []

- key: hybrid-tidal-wind
  featured: false
  status: past
  toc_title: Hybrid Tidal–Wind Feasibility (Severn Estuary)
  title: A Feasibility-Aware Portfolio for the Design & Installation of a Hybrid Tidal & Wind Farm in the Severn Estuary
  dates:
    start: 2024-09-01
    end: 2025-05-01
  role: Systems Analyst & Modeller
  domain: Renewable Energy | Offshore Engineering | Sustainability
  one_liner: >
    Bathymetry-driven siting and array modelling for a hybrid tidal–wind project in the Severn Estuary.
  summary_short: >
    Developed resource models and layouts, benchmarked LCOE, and proposed condition monitoring to reduce O&M downtime;
    results indicate competitive LCOE and improved resilience via hybridisation.
  tags: [Resource assessment, Bathymetry & GIS, Condition monitoring, Hybrid arrays, LCOE analysis, Resilience]
  stack: [Python (resource modelling, LCOE), MATLAB (turbine performance), GIS & bathymetry]
  impact_metrics:
    - { label: Capacity factor, value: "35–45%", note: "Hybrid array scenarios" }
    - { label: Site extent, value: "Barry–Minehead", note: "Bathymetry constraints" }
    - { label: LCOE, value: "£60–80/MWh", note: "Comparable to offshore wind" }
    - { label: Contribution, value: "Industrial supply", note: "Potential repowering" }
  highlights:
    - Built bathymetry and wind/tidal resource models
    - Designed arrays for capture and reliability; wake-aware spacing
    - Benchmarked LCOE under grid and O&M scenarios
    - Condition monitoring strategy to reduce downtime
  case_study:
    problem: |
      The Severn Estuary offers strong tides but complex bathymetry. Can a hybrid tidal–wind portfolio
      deliver reliable power at competitive cost for local industry?
    approach: |
      Combined bathymetry mapping with wind/tidal resource assessment to identify feasible corridors.
      Array designs balanced capture, reliability, and maintainability. Economics assessed via LCOE under multiple scenarios.
    experiments: |
      Compared tidal-only, wind-only, and hybrid layouts. Sensitivity to downtime, resource intermittency, and grid connection options.
    results: |
      Hybrid layouts smoothed supply variability, improved downtime resilience, and achieved competitive LCOE.
      The approach highlighted siting constraints around channels and shipping lanes.
    learnings:
      - Hybridisation improves reliability over single-technology fields
      - Early condition-monitoring integration reduces projected O&M costs
    next_steps:
      - High-resolution CFD; longer environmental series; extended policy-aware economics
  links: { repo: "", docs: "", demo: "", video: "", paper: "", dataset: "" }
  media:
    hero: { src: /assets/projects/hybrid/hero.jpg, alt: "Map of hybrid tidal and wind array design", caption: "Hybrid tidal–wind feasibility design" }
    gallery: []
  responsibilities:
    - Built resource and bathymetric models
    - Designed array layouts and optimised capacity factor
    - Led LCOE benchmarking and sustainability analysis
    - Proposed condition-monitoring framework
  team:
    - { name: "Group of 4 MEng students", role: "Co-designers", link: "" }

- key: fem-wing
  featured: false
  status: past
  toc_title: FEM Wing Optimisation (Composite, 2D)
  title: Finite Element Modelling and Optimisation of a 2D Composite Wing Section
  dates:
    start: 2024-02-01
    end: 2024-05-01
  role: Lead Developer & Researcher
  domain: Computational Mechanics | Optimisation | Aerospace Structures
  one_liner: >
    Custom Python FEM with differential evolution cut Von Mises stress by ~25% at <1% area error.
  summary_short: >
    Implemented 8-node quadratic elements with Gauss quadrature; θ–ϕ parametric sweeps and optimisation
    identified a robust sweet spot while enforcing area and orthotropic behaviour.
  tags: [Custom FEM, Quadratic elements, Gauss quadrature, Constraint handling, Differential evolution, Visualisation]
  stack: [Python, NumPy, SciPy (differential evolution, fsolve), Matplotlib]
  impact_metrics:
    - { label: Von Mises reduction, value: "≈25%", note: "Parametric + optimisation" }
    - { label: Area accuracy, value: "<1% error", note: "240 m² target" }
    - { label: Sweet spot, value: "θ 60–64°, ϕ 83–87°", note: "Best trade-off region" }
    - { label: Scale, value: "500+ runs", note: "Multiple materials" }
  highlights:
    - Implemented solver with 8-node quadratic elements
    - Enforced constraints via trigonometric formulation
    - Automated θ–ϕ sweeps and convergence checks
  case_study:
    problem: |
      Reduce peak stress in a composite wing section while strictly maintaining area and orthotropic response.
    approach: |
      Python FEM with Gauss quadrature; constraint enforcement via trigonometric forms and iterative solvers;
      differential evolution across θ–ϕ parameters.
    experiments: |
      Sweeps over θ, ϕ (60–90°) across material sets (E₁, E₂, G₁₂). Visualised stress fields and convergence.
    results: |
      ~25% reduction vs baselines; best region θ=60–64°, ϕ=83–87°; <1% area deviation; stress redistribution confirmed across the section.
    learnings:
      - Stability hinges on constraint enforcement and eliminating non-finite solutions
      - Small angular changes in θ have outsized effects on stress concentrations
    next_steps:
      - Extend to 3D with dynamic loads and multi-objective optimisation (stress, weight, stiffness)
  links:
    repo: https://github.com/tyecam1/AircraftWing-FEM-Solver
    docs: ""
    demo: ""
    video: ""
    paper: https://github.com/tyecam1/AircraftWing-FEM-Solver/blob/main/docs/FinalReport.pdf
    dataset: ""
  media:
    hero: { src: /assets/projects/fem-wing/hero.png, alt: "Stress contour field", caption: "Stress distribution in optimised wing section" }
    gallery: []
  responsibilities:
    - Designed and implemented FEM solver
    - Ran parametric and optimisation studies
    - Produced visualisations and final report
  team:
    - { name: "Individual project", role: "Sole developer", link: "" }

- key: rl-sumo
  featured: true
  status: past
  toc_title: RL Quadruped Sumo (ANYmal, PPO)
  title: Reinforcement Learning-Based Control of a Quadruped Agent in a Simulated Sumo Arena
  dates:
    start: 2023-08-01
    end: 2024-01-01
  role: Reinforcement Learning Engineer (course project)
  domain: Reinforcement Learning | Robotics | Simulation
  one_liner: >
    PPO + curriculum in RaisimGym; emergent leap-attack; 24th in a class tournament.
  summary_short: >
    Trained full ANYmal with torque control and curriculum scheduling; analysed learning curves and strategies.
  tags: [PPO, Curriculum learning, Vectorised envs, Reward shaping, Emergent behaviour, Analysis]
  stack: [PyTorch, RaiSim/RaisimGym, CUDA, NumPy, TensorBoard]
  impact_metrics:
    - { label: Placement, value: "24th", note: "MSc/PhD cohort tournament" }
    - { label: Scale, value: "1M+ iters", note: "Vectorised environments" }
    - { label: Behaviours, value: "Leap-attack, edge pushing", note: "Emergent, not scripted" }
  highlights:
    - Implemented PPO baseline and curriculum scheduler
    - Reward shaping for stance stability and opponent displacement
    - Full-model ANYmal training with joint torque actuation
  case_study:
    problem: |
      Quadruped control in adversarial contact settings is high-variance and sparse-reward.
    approach: |
      PPO in PyTorch with vectorised environments and curriculum difficulty; observations include joint states and opponent proximity.
    experiments: |
      Baseline PPO vs curriculum; measured win rate and reward progression; qualitative behaviour analysis.
    results: |
      Curriculum accelerated convergence and improved robustness; policies discovered leap-attack and edge-pushing tactics.
    learnings:
      - Curriculum design materially affects sample efficiency
      - Visualisation and component rewards are critical for debugging
    next_steps:
      - Multi-agent self-play and domain randomisation for robustness
  links:
    repo: https://github.com/tyecam1/KAIST-Anymal-Sumo
    docs: ""
    demo: ""
    video: ""
    paper: https://github.com/tyecam1/KAIST-Anymal-Sumo/blob/master/ME491_project/report/TyeCameronFinalReport.pdf
    dataset: ""
  media:
    hero: { src: /assets/projects/rl-sumo/hero.jpg, alt: "ANYmal robots in a simulated sumo arena", caption: "ANYmal trained with PPO in RaisimGym" }
    gallery: []
  responsibilities:
    - Implemented PPO loop and curriculum
    - Tuned reward shaping and environment configuration
    - Ran GPU training and analysed behaviours
  team: []
  references:
    - https://github.com/jhwangbo/raisimLib
    - https://github.com/jhwangbo/ME491_Policy_Iteration
    - https://github.com/jhwangbo/ME491_Value_Iteration_Template
    - https://github.com/jhwangbo/raisimGymTutorial
