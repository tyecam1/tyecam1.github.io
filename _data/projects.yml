# ==========================
# CURRENT / IN-PROGRESS (concise)
# ==========================

- key: rl-telemetry
  featured: false
  status: current
  toc_title: Simulation & Telemetry Platform
  title: Integrated RL Simulation & Telemetry Platform
  dates:
    start: 2025-09-01
  role: Developer & Research Engineer
  domain: Reinforcement Learning
  one_liner: >
    Unified RL pipeline for 2D/3D tasks with live telemetry and reproducible runs.
  summary_short: >
    A telemetry platform that displays live metrics, logs, and video frames for simulated 2-D and 3-D reinforcement-learning agents.
  tags: [RL platforms, Reproducibility, Telemetry, Robotics]
  stack: [Python, PyTorch, Gymnasium, Unity ML-Agents, PyBullet, Flask/Streamlit, WebSocket, Docker]
  impact_metrics:
    - { label: "Metric update latency (95th percentile)", value: "tbd", note: "Time from the training process emitting a metric to it appearing in the dashboard" }
    - { label: "Metric delivery success", value: "tbd", note: "Percentage of expected metric points that arrive (counts missing updates over the run)" }
    - { label: "Video frame drop rate", value: "tbd", note: "Percentage of frames lost between the environment stream and the dashboard" }
  highlights:
    - "Same calls to start a task, take an action, and view the screen across every environment"
    - "Stream live training numbers and video frames to the web dashboard"
    - "Save everything needed to rerun an experiment (settings, seed, code version, metrics, checkpoints)"
  case_study:
    problem: >
      I want something I can carry into future projects, and a centralised telemetry platform will consolidate project logs
      and streamline progress.
    approach: >
      Start deliberately small: build a simple 2-D reinforcement-learning maze solver and use it
      to stand up the display. Keep everything observable: emit metrics, logs, and video frames;
      save the settings, random seed, code version, and checkpoints; and grow the system as I
      learn more about reinforcement learning and web development.
    results: >
      Baseline Proximal Policy Optimisation with live telemetry is operational on 2-D tasks;
      3-D environments are integrated and tuning is in progress.
    next_steps:
      - "Create a clean repository structure and minimal documentation"
      - "Define a small, stable telemetry format (metrics, logs, video frames)"
      - "Implement the 2-D maze environment and a simple baseline agent"
      - "Wire the data path end-to-end (trainer → collector → dashboard)"
      - "Record run artefacts by default (settings, seed, code version, checkpoints)"
      - "Add basic tests and set up continuous integration"
  links: { repo: "", docs: "", demo: "", video: "", paper: "", dataset: "" }
  media:
    hero: { src: /assets/img/rl-telemetry/hero.png, alt: "RL platform system diagram", caption: "Planned architecture and telemetry" }
    gallery: []
  responsibilities:
    - "Designing the initial architecture and a RL baseline to sanity-check the pipeline"
    - "Implementing structured logging, checkpoints, and run artefact capture (settings, seed, code version) for reproducibility"
    - "Building the telemetry path—trainer → collector → web dashboard—streaming metrics and environment video frames"
    - "Integrating environment backends (Gymnasium for 2-D, PyBullet for 3-D) behind a small, consistent wrapper"
  team: []

- key: archlinux-migration
  featured: false
  status: current
  toc_title: Arch Linux Migration
  title: Arch Linux Migration & Dev Environment Automation
  dates:
    start: 2025-10-01
  role: Systems Engineer (personal infrastructure)
  domain: Developer Experience | Linux
  one_liner: >
    NVIDIA 3060 laptop on Arch: reproducible, CUDA-ready, one-command bootstrap.
  summary_short: >
    Scripted install (bootloader→CUDA→Docker→dotfiles) plus an optional Ansible playbook for idempotent rebuilds.
  tags: [Linux, CUDA, Docker, Dotfiles, Automation, Ansible]
  stack: [Arch Linux, systemd-boot, btrfs, pacman/paru, NVIDIA, Docker, Python, Make, Ansible]
  impact_metrics:
    - { label: Bootstrap, value: "≤15 min", note: "Bare OS → dev ready" }
    - { label: Repro, value: "1 command", note: "make bootstrap" }
    - { label: GPU, value: "CUDA OK", note: "Validate on host + Docker" }
  highlights:
    - Idempotent shell bootstrap for packages, drivers, and tools
    - Versioned dotfiles (shell/editor/terminal/WM)
    - Docker workflow for RL/robotics stacks
    - Ansible playbook with roles, handlers, and tags against a local or remote inventory
  case_study:
    problem: >
      Windows made GPU training and reproducibility fragile and slow. I want a lean Linux
      workstation I can rebuild from scratch at any time, same tools, same drivers, so progress
      isn’t blocked by the machine. I’ll start on my second-hand 3060 laptop I'd acquired for RL in South Korea, so breakage is safe.
    approach: >
      Use Arch Linux with everything written and designed as code. Automate the full stack: bootloader,
      disk layout and filesystem, NVIDIA drivers, packages, dotfiles, containers, and the
      Python toolchain; mirror the process in Ansible for unattended reinstalls on new
      hardware or a clean disk.
    results: >
      One-command setup produces a clean desktop with working NVIDIA CUDA, my editor and shell,
      and a predictable Python environment. Context switching is faster, and the same playbook
      can bring up a headless node or a second machine.
    next_steps:
      - "Publish the bootstrap and dotfiles with basic checks in continuous integration"
      - "Add smoke tests: driver loads, nvidia-smi works, CUDA sample compiles"
      - "Script simple backup and sync across machines (home and project folders)"
  links: { repo: "", docs: "", demo: "", video: "", paper: "", dataset: "" }
  media:
    hero: { src: /assets/projects/archlinux/hero.png, alt: "Arch desktop with terminal and telemetry", caption: "Reproducible CUDA dev environment" }
    gallery: []
  responsibilities:
    - Code custom desktop environment
    - Author bootstrap and dotfiles
    - Validate CUDA on host and Docker
    - Write Ansible roles and inventory
  team: []

- key: phd-planning
  featured: false
  status: current
  toc_title: "PhD Planning: Robot Learning"
  title: "PhD Planning: Robot Learning for Human Robot Collaboration"
  dates:
    start: 2025-09-01
  role: Candidate (self-directed research planning)
  domain: Robot Learning | HRI
  one_liner: >
    Long-term interest: safe, co-adaptive RL for human-in-the-loop technology—pursued alongside a full-time role.
  summary_short: >
    Proposals, reading plan, small prototypes; outreach to European HRI labs.
  tags: [Safe RL, Co-adaptive control, Intent estimation, Datasets for RL, Reproducibility]
  stack: [Python, PyTorch, ROS, Unity/Gazebo, Jupyter, Zotero]
  impact_metrics:
    - { label: Proposals, value: "2–3", note: "Framing + methods" }
    - { label: Prototypes, value: "tbd", note: "Navigation + eval demos" }
    - { label: Reading, value: "50 ATM", note: "With notes" }
  highlights:
    - Problem axes defined (uncertainty, perception ambiguity, human-in-loop)
    - Reproducible experiment & evaluation plan
    - Prototypes to de-risk perception and reward design
  case_study:
    problem: >
      Robots can execute narrow tasks quickly, but they lack the directive a human provides.
      For robots and people to work together in the physical world, we need practical, two-way
      communication and safe co-adaptation. Reinforcement-learning for human–robot interaction
      (HRI) is promising, but the required data are costly to collect and often bespoke, which
      makes results hard to compare and reuse.
    approach: >
      Map what works today and build on it. Start with small, reproducible studies that combine:
      (1) uncertainty-aware perception and intent inference, (2) co-adaptive control with
      safety constraints, and (3) preference-informed learning to keep humans in the loop.
      Control data costs by prototyping in simulation first (Unity/Gazebo), using scripted user
      models and teleoperation for early signals, then moving to focused human studies.
    results: >
      Long term planning outcomes to aim for: a coherent, defensible PhD plan (research questions, methods,
      and evaluation) and a successful studentship application with a respected robotics/HRI group.
      Current status: Limited to research only while I persue a career in my field.
    next_steps:
      - "Sharpen the primary research question and success criteria"
      - "Build a small simulation task to test co-adaptation and intent cues"
      - "Set up a reproducible template repo (tasks, logging, seeds, metrics, notebooks)"

  links: { repo: "", docs: "", demo: "", video: "", paper: "", dataset: "" }
  media:
    hero: { src: /assets/projects/phd/hero.png, alt: "Planning board and prototype screenshots", caption: "Themes, prototypes, and evaluation plan" }
    gallery: []
  responsibilities:
    - Draft proposals and reading plan
  team: []

# ==========================
# PAST / COMPLETED (expanded)
# ==========================

- key: walkaide
  featured: true
  status: past
  toc_title: Wearable Navigation System
  title: The Design and Evaluation of Haptic Feedback Methods and Environmental Impacts on a Wearable Navigation System
  dates:
    start: 2024-09-01
    end: 2025-05-01
  role: Systems Engineer
  domain: Robotics | Assistive Robotics | Haptics | VSLAM | Human Factors
  one_liner: >
    A comparitive study on two haptic feedback methods for a wearable navigation aid used by the visually impaired.
  summary_short: >
    Built a wearable navigation system (RGB-D VSLAM, APF navigation, haptic actuation) with EEG event logging. Trials showed
    fixed reference haptic cues outperformed rotational haptic ques on success, safety, and reaction time.
  tags:
    - SLAM
    - ROS Noetic
    - Python (custom ROS nodes, PCL)
    - RTAB-Map (RGB-D VSLAM)
    - Intel RealSense D435i
    - Arduino Nano 33 BLE
    - LattePanda Delta 3
    - Raspberry Pi 4
    - EEG logging (Emotiv, CYKIT)
    - Artificial Potential Fields (navigation)
  stack:
    - ROS Noetic
    - Python (custom ROS nodes, PCL)
    - RTAB-Map (RGB-D VSLAM)
    - Intel RealSense D435i
    - Arduino Nano 33 BLE
    - EEG logging (Emotiv, CYKIT)
  impact_metrics:
    - { label: Success rate, value: "83–77% vs 50–66%", note: "Compass vs pulling" }
    - { label: Collisions per trial, value: "0–0.42 vs up to 1.17", note: "Compass vs pulling" }
    - { label: Reaction time, value: "3.43–3.67 s vs ~4.5–4.9 s", note: "Compass vs pulling feedback" }
    - { label: Participants, value: "4", note: "Blindfolded indoor trials (textured vs plain)" }
  highlights:
    - End-to-end lightweight wearable system with RGB-D perception, VSLAM, haptic navigation
    - Controlled comparison of compass vs rotational-based feedback
    - EEG event logging aligned to haptic navigation cues for later analysis
    - Reproducible ROS/Arduino testbed for assistive robotics
  case_study:
    problem: |
      Indoors, GPS is unreliable. According to cognitive science, we understand haptic feedback best when a fixed reference point is utilised.
      However, our mobbility is naturally coordinated through left and right channels. Will fixed reference point haptic cues, paired with RGB-D SLAM, 
      guide users more clearly than pull-based rotational ques? What are the other critical factors in wearable navigation systems?
    approach: |
      ROS pipeline with RealSense RGB-D perception, RTAB-Map localisation, APF navigation, and Arduino-driven actuators.
      Two feedback modalities were implemented: (i) compass pressure with a back reference, and (ii) tightening straps around either shoulder.
      All cues and motor commands were timestamped and logged, together with EEG event markers, for later cognitive workload analysis.
    experiments: |
      Four blindfolded participants navigated fixed routes in textured and plain rooms with both systems and 3 distinct obstacles.
      Metrics included success, collisions, odometry loss, reaction time, and qualitative feedback. SLAM stability was
      analysed under texture and turning-rate changes.
    results: |
      Compass cues achieved higher success (83–77% vs 50–66%), fewer collisions (0–0.42 vs ≤1.17), and faster reactions
      (3.4–3.7 s vs ~4.5–4.9 s). Textured environments stabilised VSLAM, while rapid turns remained a failure mode.
      Participants reported compass cues clearer and more distinguishable; pulling was rated more natural and comfortable.
    challenges:
      - Limited servo torque constrained haptic salience
      - VSLAM degraded during rapid turns and in plain environments
      - Small sample size limited statistical power
      - Multi-device ROS over Wi-Fi/TF frames introduced timing complexity
    learnings:
      - Body-referenced compass cues are clearer than pull-based cues indoors
      - Visual texture drives VSLAM latency more than move speed
      - Event-synchronised EEG logging is practical and informative for later analysis
    next_steps:
      - Lighter, higher-torque actuators with adaptive feedback
      - Multi-camera or fusion for robust SLAM; larger participant study
  links:
    repo: https://github.com/tyecam1/Mechatronic-Walkaide
    docs: ""
    demo: ""
    video: ""
    paper: https://github.com/tyecam1/Mechatronic-Walkaide/blob/main/Report%20Write%20Up/WearableNavigationAid-FinalReport.pdf
    dataset: ""
  media:
    hero: { src: /assets/img/walkaide.png, alt: "Participant wearing haptic harness with RGB-D camera", caption: "Prototype wearable navigation system" }
    gallery:
      - { src: /assets/img/walkaide2.png, alt: "Electronics & harness layout", caption: "Electronics & harness" }
      - { src: /assets/img/walkaide3.png, alt: "Project poster", caption: "Poster" }
      - { src: /assets/img/walkaide4.png, alt: "Navigation scene with obstacles", caption: "Navigation scene" }
      - { src: /assets/img/walkaide6.png, alt: "Trial still", caption: "Trial still" }
  videos:
    - id: hjoRbiRpzas
      title: Haptic Feedback Methods and Environmental Impacts — Testing
  responsibilities:
    - Designed system architecture and custom ROS nodes
    - Implemented APF navigation and haptic control
    - Integrated VSLAM perception, mapping, and Arduino feedback
    - Tuned parameters, optimised for system latency and robustness
    - Implemented EEG logging & synchronisation; handed over for analysis
  team: ["Trystan Barnett (Electrical) ", "Tye Cameron (Systems) ", "Oscar Meads (Electrical) ", "Dylan Williams (Mechanical) ", "Shou-Han Zhou (Supervisor)"]

- key: hybrid-tidal-wind
  featured: false
  status: past
  toc_title: Severn Estuary Wind & Tidal Feasibility
  title: A Feasibility-Aware Portfolio for the Design & Installation of a Hybrid Tidal & Wind Farm in the Severn Estuary
  dates:
    start: 2024-09-01
    end: 2025-05-01
  role: Resource & Array Modelling · Condition Monitoring · Financial Analysis
  domain: Renewable Energy | Offshore Engineering | Sustainability
  one_liner: >
    Feasibility study comparing tidal, wind, and hybrid options in the Severn Estuary; hybrid was
    assessed but wind-only was recommended as most feasible and lowest cost.
  summary_short: >
    Mapped bathymetry and resources, designed wind layouts (21 × 15 MW) with wake-aware spacing,
    routed inter-array cabling, and scoped grid/substation options. Tidal potential was analysed
    but co-location proved impractical; the wind-only design achieved the lowest LCOE under the
    stated assumptions.
  tags: [Resource assessment, Bathymetry & GIS, Condition monitoring, Hybrid assessment, LCOE analysis, Resilience]
  stack: [Python (PyWake, LCOE), SciPy (optimisation), MATLAB (turbine performance), GIS & bathymetry]
  impact_metrics:
    - { label: Installed capacity, value: "315 MW", note: "21 × Vestas V236-15 MW" }
    - { label: Annual energy, value: "≈ 1,344 GWh/yr", note: "Study AEP estimate" }
    - { label: Capacity factor, value: "≈ 48.8%", note: "Assumed for site" }
    - { label: LCOE (baseline), value: "≈ £65/MWh", note: "Modelled; sensitive to discount rate" }
  highlights:
    - Built bathymetry and wind/tidal resource layers and mapped feasible corridors
    - "Wind layout: west-oriented rows, ~7D × 4D spacing; Jensen/Park with Gaussian follow-up checks"
    - Cable routing via MST + differential evolution; grid as MVAC with a single onshore substation
    - Condition-monitoring costs and OPEX assumptions included to inform downtime and LCOE
  case_study:
    problem: >
      The Severn Estuary has strong tidal flows but complex bathymetry and strict siting constraints.
      The question: can a hybrid tidal–wind portfolio deliver reliable power for local industry at a
      competitive cost once channels, shipping lanes, wildlife zones, and seabed conditions are respected?
    approach: >
      Integrate bathymetry and resource data to map feasible corridors; design wind layouts and preliminarily
      size foundations; model wakes and array spacing; optimise inter-array cable routing; and design grid and
      substation options. Assess economics via levelised cost of energy with sensitivity to downtime and intermittency.
    experiments:
      - Compare tidal-only, wind-only, and hybrid layouts at candidate sites
      - Sweep spacing/orientation and cable topologies to trade off yield, losses, and maintainability
      - Test sensitivity to device availability, maintenance windows, and grid-connection distance/tariffs
    results: >
      Wind-only layouts achieved the lowest levelised cost of energy under the study assumptions. Economies of
      scale in turbine ratings, installation vessels, O&M logistics, and a mature supply chain dominated. Hybrid
      layouts offered smoother supply but were impractical here due to depth, seabed, and electrical-integration
      mismatches, and came with higher LCOE. Siting constraints around channels and shipping lanes remained key drivers.
    learnings:
      - "Wind-only is most cost-effective at this site; hybridisation improves reliability but adds cost/complexity"
      - "Early condition-monitoring integration reduces projected O&M costs"
      - "Cable routing and substation siting materially affect both losses and installation costs"
    next_steps:
      - "Higher-resolution CFD for wakes and local bathymetry effects"
      - "Longer multi-year environmental series to stress-test variability and downtime"
      - "Policy-aware economics (e.g., Contracts for Difference scenarios) and refined CAPEX/OPEX ranges"
      - "Early engagement with navigation and wildlife stakeholders to validate corridors and exclusions"
  links: { repo: "", docs: "", demo: "", video: "", paper: "", dataset: "" }
  media:
    hero: { src: /assets/projects/img/tidal-array.png, alt: "Google Earth rendering of the optimised tidal array", caption: "Google Earth rendering of the optimised tidal array"}
    gallery: []
  videos:
    - id: R84wCpUQfaM
      title: Renewable Energy Park Design Documentary
  responsibilities:
    - Built resource and bathymetric models
    - Designed array layouts and optimised capacity factor
    - Led LCOE benchmarking and sustainability analysis
    - Proposed condition-monitoring framework
  team: ["Imogen Anderson (Civil) ", "Victoria Bridges-Galvez (Civil) ", "Tye Cameron (Mechanical) ", "Tom Daniels (Mechanical) ", "Valerija Kolosova (Civil) ", "Jack Tricklebank (Mechanical) "]

- key: fem-wing
  featured: false
  status: past
  toc_title: FEM Wing Optimisation
  title: Finite Element Modelling and Optimisation of a 2D Composite Wing Section
  dates:
    start: 2024-02-01
    end: 2024-05-01
  role: Lead Developer & Researcher
  domain: Computational Mechanics | Optimisation | Aerospace Structures
  one_liner: >
    Custom Python FEM with differential evolution cut Von Mises stress by ~25% at <1% area error.
  summary_short: >
    Implemented 8-node quadratic elements with Gauss quadrature; θ–ϕ parametric sweeps and optimisation
    identified a robust sweet spot while enforcing area and orthotropic behaviour.
  tags: [Custom FEM, Quadratic elements, Gauss quadrature, Constraint handling, Differential evolution, ParaView Visualisation]
  stack: [Python, NumPy, SciPy (differential evolution, fsolve), Matplotlib, ParaView, Gmsh]
  impact_metrics:
    - { label: Von Mises reduction, value: "≈25%", note: "Parametric + optimisation" }
    - { label: Area accuracy, value: "<1% error", note: "240 m² target" }
    - { label: Sweet spot, value: "θ 60–64°, ϕ 83–87°", note: "Best trade-off region" }
    - { label: Scale, value: "500+ runs", note: "Multiple materials" }
  highlights:
    - Implemented solver with 8-node quadratic elements
    - Efficient sparse stiffness matrix handling
    - Automated θ–ϕ sweeps and convergence checks
  case_study:
    problem: |
      Reduce peak stress in a composite wing section while strictly maintaining area and orthotropic response.
    approach: |
      Python FEM with Gauss quadrature; constraint enforcement via trigonometric forms and iterative solvers;
      differential evolution across θ–ϕ parameters.
    experiments: |
      Sweeps over θ, ϕ (60–90°) across material sets (E₁, E₂, G₁₂). Visualised stress fields and convergence.
    results: |
      ~25% reduction vs baselines; best region θ=60–64°, ϕ=83–87°; <1% area deviation; stress redistribution confirmed across the section.
    learnings:
      - Stability hinges on constraint enforcement and eliminating non-finite solutions
      - Small angular changes in θ have outsized effects on stress concentrations
    next_steps:
      - Extend to 3D with dynamic loads and multi-objective optimisation (stress, weight, stiffness)
  links:
    repo: https://github.com/tyecam1/AircraftWing-FEM-Solver
    docs: ""
    demo: ""
    video: ""
    paper: https://github.com/tyecam1/AircraftWing-FEM-Solver/blob/main/docs/FinalReport.pdf
    dataset: ""
  media:
    hero: { src: /assets/img/fem-wing-hero-MaxVM.png, alt: "Von Mises stress field (max VM)", caption: "Max Von Mises stress in composite wing" }
    gallery:
      - { src: /assets/img/fem-wing-4NodeComparison.png, alt: "4-node quadratic elements", caption: "4-node quadratic elements" }
      - { src: /assets/img/fem-wing-8NodedComparison.png, alt: "8-node quadratic elements", caption: "8-node quadratic elements" }
      - { src: /assets/img/fem-wing-EigenVec1.png, alt: "Eigenvector mode 1", caption: "Eigenvector 1" }
      - { src: /assets/img/fem-wing-EigenVec2.png, alt: "Eigenvector mode 2", caption: "Eigenvector 2" }
      - { src: /assets/img/fem-wing-MaxPrincipleShear.png, alt: "Max principal shear", caption: "Max principal shear" }
      - { src: /assets/img/fem-wing-PrincipleSurface.png, alt: "Principal stress surface", caption: "Principal stress surface" }
      - { src: /assets/img/fem-wing-stressXX.png, alt: "σxx stress field", caption: "Stress XX" }
      - { src: /assets/img/fem-wing-stressYY.png, alt: "σyy stress field", caption: "Stress YY" }
      - { src: /assets/img/fem-wing-VMsurface.png, alt: "Von Mises surface", caption: "Von Mises surface" }
  responsibilities:
    - Designed and implemented FEM solver
    - Ran parametric and optimisation studies
    - Produced visualisations and final report
  team: Individual project

- key: rl-sumo
  featured: true
  status: past
  toc_title: RL Quadruped Sumo
  title: Reinforcement Learning-Based Control of a Quadruped Agent in a Simulated Sumo Arena
  dates:
    start: 2023-08-01
    end: 2024-01-01
  role: Reinforcement Learning Engineer (course project)
  domain: Reinforcement Learning | Robotics | Simulation
  one_liner: >
    Proximal Policy Optimisation (PPO) with a simple, reward-embedded curriculum in RaisimGym; an emergent
    “leap” opening appeared.
  summary_short: >
    Trained full ANYmal with joint-torque control and a two-stage curriculum; analysed learning curves,
    hyperparameters, and emergent tactics under adversarial contact.
  tags: [PPO, Curriculum learning, Vectorised envs, Reward shaping, Emergent behaviour, Analysis]
  stack: [PyTorch, RaiSim/RaisimGym, CUDA, NumPy, TensorBoard]
  impact_metrics:
    - { label: Placement,  value: "24/32",      note: "Tournament placing (25% win rate)" }
    - { label: Scale,      value: "100 envs",   note: "Vectorised training; 30 threads" }
    - { label: Behaviour,  value: "Leap-attack", note: "Discovered early; often decisive but risky" }
  highlights:
    - Implemented PPO baseline in PyTorch with vectorised simulation and a two-stage curriculum
    - Shaped rewards for stability, useful approach, impact, and centre control; tuned γ=0.998 and λ=0.95
    - Observed emergent “leap” opener plus edge-pushing; diagnosed failure cases and reward side-effects
  case_study:
    problem: |
      Quadruped control under adversarial contact is high-variance and sparse-reward. The agent must
      balance stability and aggression in continuous action space while avoiding brittle policy updates.
    approach: |
      Train with Proximal Policy Optimisation in PyTorch on a vectorised RaiSim/RaisimGym environment
      (100 parallel arenas). Use a simple curriculum embedded in the reward: far from centre → emphasise
      approach/impact and forward velocity; near centre → emphasise stability/centre control. Include
      reward terms for torque cost, centre-of-mass height, and body pitch. Tune PPO with γ=0.998, λ=0.95.
    experiments:
      - Baseline PPO vs. curriculum-augmented PPO; measure win rate, reward progression, and stability proxies
      - Ablate reward terms (impact, useful-distance, stabilisers) to expose side-effects
      - Qualitative analysis of emergent tactics (opening leaps, edge pushing) and failure modes
    results: |
      The curriculum accelerated early learning and improved robustness relative to the baseline.
      Policies discovered a high-impact “leap” opener and edge-pushing behaviour. In evaluation,
      placement was 24/32 with ~25% win rate; failures were often self-destabilisations after the leap.
    learnings:
      - “Contact = good” accidentally encourages sticking to the opponent; reward should favour destabilisation, not mere impact
      - Curriculum design matters; centre-aware staging improved sample efficiency and stability
      - Limited opponent diversity in training capped generalisation; richer opponents are needed
    next_steps:
      - "Introduce self-play and opponent ensembles; apply domain randomisation for contact, friction, and mass"
      - "Rework reward to penalise sustained contact and explicitly reward opponent destabilisation/outs"
      - "Add safety terms (anti-flip) and richer observations; explore longer horizons and early-stopping criteria"
  links:
    repo: https://github.com/tyecam1/KAIST-Anymal-Sumo
    docs: ""
    demo: ""
    video: ""
    paper: https://github.com/tyecam1/KAIST-Anymal-Sumo/blob/master/ME491_project/report/TyeCameronFinalReport.pdf
    dataset: ""
  media:
    hero: { src: /assets/img/anymal-sumo-hero.png, alt: "ANYmal robots in a simulated sumo arena", caption: "ANYmal trained with PPO in RaisimGym" }
    gallery:
      - { src: /assets/img/anymal-sumo-2-boxTraining.jpg, alt: "ANYmal in box training stage", caption: "Curriculum: box training" }
      - { src: /assets/img/anymal-sumo-3-ArenaLayout.png, alt: "Top-down of the sumo arena", caption: "Arena layout" }
      - { src: /assets/img/anymal-sumo-4-Demo.png, alt: "Demo match still", caption: "Demo bout" }
  responsibilities:
    - Implemented PPO loop and two-stage curriculum; tuned γ, λ, action std, and reward coefficients
    - Shaped rewards for stability vs aggression; instrumented training and analysed behaviours
    - Ran GPU training, evaluated policies, and documented tournament results
  team: []
  references:
    - https://github.com/jhwangbo/raisimLib
    - https://github.com/jhwangbo/ME491_Policy_Iteration
    - https://github.com/jhwangbo/ME491_Value_Iteration_Template
    - https://github.com/jhwangbo/raisimGymTutorial
  videos:
    - id: x24TwcXVaeE
      title: Initial ANYmal Agent training video

